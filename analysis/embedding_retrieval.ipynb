{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideally, you'll only run this file once when you have a new pull of the data etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vislearnlabpy.embeddings.generate_embeddings import EmbeddingGenerator\n",
    "from vislearnlabpy.embeddings.embedding_store import EmbeddingStore\n",
    "from vislearnlabpy.embeddings.stimuli_loader import ImageExtractor, ImgExtractionSettings\n",
    "from vislearnlabpy.embeddings.utils import display_search_results, zscore_embeddings, filter_embeddings \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction settings and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_extraction_settings = ImgExtractionSettings(\n",
    "        resize_dim=104,\n",
    "        apply_content_crop=True,\n",
    "        apply_center_crop=False,\n",
    "        use_thumbnail=False,\n",
    "        filter_edge_artifacts=False,\n",
    "        normalize_stroke_thickness=True,\n",
    "        stroke_target_thickness=1,\n",
    "        bg_component_size=1,\n",
    "        double_resize=False\n",
    "    )\n",
    "# different settings for Kisumu images to handle higher resolution \n",
    "kisumu_extraction_settings = ImgExtractionSettings(\n",
    "        resize_dim=104,\n",
    "        apply_content_crop=True,\n",
    "        apply_center_crop=False,\n",
    "        use_thumbnail=True,\n",
    "        filter_edge_artifacts=False,\n",
    "        normalize_stroke_thickness=True,\n",
    "        stroke_target_thickness=1.7,\n",
    "        bg_component_size=1,\n",
    "        double_resize=True\n",
    "    )\n",
    "# clip extraction settings after resizing\n",
    "clip_extraction_settings = ImgExtractionSettings(\n",
    "        resize_dim=224,\n",
    "        apply_content_crop=True,\n",
    "        bg_component_size=0,\n",
    "        apply_center_crop=False,\n",
    "        use_thumbnail=False,\n",
    "        filter_edge_artifacts=False,\n",
    "        normalize_stroke_thickness=False\n",
    ")\n",
    "clip_transforms = ImageExtractor.get_transformations(clip_extraction_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_generator = EmbeddingGenerator(model_type=\"clip\", device=\"mps\", output_type=\"doc\", transform=clip_transforms) # change device=\"cpu\" if you are using"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing image extraction settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ImageExtractor.save_transformed(\"/Volumes/vislearnlab/experiments/drawing/data/newdelhi/sketches_full_dataset/a_rabbit/a_rabbit_sketch_HP355_newdelhi_run_v11757310528711.png\", \"../data/examples/newdelhi_example.png\", general_extraction_settings)\n",
    "ImageExtractor.save_transformed(\"/Volumes/vislearnlab/experiments/drawing/data/beijing/object_drawings/S_chair_sketch_age9_sanjose_photodraw_e21550773711411.png\", \"../data/examples/sanjose_example.png\", general_extraction_settings)\n",
    "ImageExtractor.save_transformed(\"/Volumes/vislearnlab/experiments/drawing/data/beijing/object_drawings/P_airplane_sketch_age5_IPAD4_THU5F2.png\", \"../data/examples/beijing_example.png\", general_extraction_settings)\n",
    "ImageExtractor.save_transformed(\"/Volumes/vislearnlab/experiments/drawing/data/kisumu/transformed_drawings/S52_age3_House_trial010.png\", \"../data/examples/kisumu_example.png\", kisumu_extraction_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting drawings across sites. newdelhi drawings are linked to subject data csv to get age information, but rest have that information within the urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawings_folder = Path(\"/Volumes/vislearnlab/experiments/drawing/data\")\n",
    "beijing_dir = drawings_folder / Path(\"beijing/object_drawings\")\n",
    "beijing_resized_dir = drawings_folder / Path(\"beijing/resized_drawings\")\n",
    "kisumu_dir = drawings_folder / Path(\"kisumu/drawings\")\n",
    "kisumu_cropped_drawings_path = drawings_folder / Path(\"kisumu/transformed_drawings\")\n",
    "kisumu_resized_dir = drawings_folder / Path(\"kisumu/resized_drawings\")\n",
    "newdelhi_dir = drawings_folder / Path(\"india/sketches_full_dataset\")\n",
    "newdelhi_resized_dir = drawings_folder / Path(\"india/resized_sketches_full_dataset\")\n",
    "newdelhi_df = pd.read_csv(drawings_folder / Path(\"india/AllDescriptives_images_final_india_run_v1.csv\"))\n",
    "newdelhi_subject_data = pd.read_csv(Path(\"/Volumes/vislearnlab/experiments/drawing/data/india/subject_data.csv\"))\n",
    "categories = [\"airplane\", \"bike\", \"bird\", \"car\", \"cat\", \"chair\", \"cup\", \"hat\", \"house\", \"rabbit\", \"tree\", \"watch\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resizing and cropping drawings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "kisumu_cropped_drawings_path = Path(\"/Volumes/vislearnlab/experiments/drawing/data/kisumu/transformed_drawings\")\n",
    "os.makedirs(kisumu_cropped_drawings_path, exist_ok=True)\n",
    "kisumu_extraction_settings = ImgExtractionSettings(apply_center_crop=True, crop_dim=1400, change_stroke_color=True, bg_threshold=1, bg_component_size=100, filter_edge_artifacts=True)\n",
    "for img_path in tqdm(kisumu_dir.glob(\"*.png\"), total=len(list(kisumu_dir.glob(\"*.png\")))):\n",
    "    # if (img_path.name == \"S52_age3_House_trial010.png\"):\n",
    "    new_path = kisumu_cropped_drawings_path / img_path.name\n",
    "    if not img_path.name.startswith(\".\") and not new_path.exists():\n",
    "        ImageExtractor.save_transformed(img_path, new_path, kisumu_extraction_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def resize_drawings(input_dir, output_dir, extraction_settings):\n",
    "    input_dir = Path(input_dir)\n",
    "    output_dir = Path(output_dir)\n",
    "    img_paths = list(input_dir.glob(\"**/*.png\"))\n",
    "    for img_path in tqdm(img_paths, total=len(img_paths)):\n",
    "        # Preserve subdirectory structure\n",
    "        relative_path = img_path.relative_to(input_dir)\n",
    "        new_path = output_dir / relative_path\n",
    "        # Create parent directories if they don't exist\n",
    "        new_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        if not img_path.name.startswith(\".\") and not new_path.exists():\n",
    "            try:\n",
    "                ImageExtractor.save_transformed(img_path, new_path, extraction_settings)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {img_path}: {e}\")\n",
    "                ImageExtractor.save_transformed(img_path, new_path, None)\n",
    "   \n",
    "\n",
    "resize_drawings(newdelhi_dir, newdelhi_resized_dir, general_extraction_settings)\n",
    "resize_drawings(kisumu_cropped_drawings_path, kisumu_resized_dir, kisumu_extraction_settings)\n",
    "resize_drawings(beijing_dir, beijing_resized_dir, general_extraction_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beijing and sanjose within the same folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_generator.generate_image_embeddings(output_path=\"beijing_sanjose_drawings_resized\", input_dir=beijing_resized_dir, batch_size=100, overwrite=True)\n",
    "clip_generator.generate_image_embeddings(output_path=\"beijing_sanjose_drawings\", input_dir=beijing_dir, batch_size=100, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kisumu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_generator.generate_image_embeddings(output_path=\"kisumu_drawings_resized\", input_dir=kisumu_resized_dir, batch_size=100, overwrite=True)\n",
    "clip_generator.generate_image_embeddings(output_path=\"kisumu_drawings\", input_dir=kisumu_cropped_drawings_path, batch_size=100, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now grabbing newdelhi drawings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_pids = newdelhi_subject_data[newdelhi_subject_data[\"Age (months)\"] > 0][\"PID\"].unique().tolist()\n",
    "print(f\"Number of participants: {len(valid_pids)}\")\n",
    "newdelhi_df = newdelhi_df.rename(columns={\n",
    "    'filename': 'image1',\n",
    "    'category': 'text1'\n",
    "})\n",
    "# getting rid of articles\n",
    "newdelhi_df['text1'] = newdelhi_df['text1'].apply(lambda x: \" \".join(x.split('_')))\n",
    "#newdelhi_df['image1'] = newdelhi_df['image1'].apply(lambda x: x.replace(\"sketches_full_dataset\", \"resized_sketches_full_dataset\"))\n",
    "#remap path if needed: new_base=\"/file/storage/path\"\n",
    "#drawings_df[\"image1\"] = drawings_df[\"image1\"].apply(lambda x: remap_path(x, new_base))\n",
    "\n",
    "# Filtering to just our actual participants\n",
    "filtered_df = newdelhi_df[newdelhi_df['participant_id'].str.upper().isin(valid_pids)]\n",
    "filtered_df.to_csv(\"tmp_draw_df.csv\")\n",
    "#clip_generator.generate_image_embeddings(output_path=\"newdelhi_drawings_resized\", input_csv=\"tmp_draw_df.csv\", batch_size=100, overwrite=True)\n",
    "clip_generator.generate_image_embeddings(output_path=\"newdelhi_drawings\", input_csv=\"tmp_draw_df.csv\", batch_size=100, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now getting the text embeddings for each category using the prompt 'drawing of a..' (miss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdelhi_store = EmbeddingStore.from_doc(\"newdelhi_drawings_resized/image_embeddings/clip_image_embeddings_doc\")\n",
    "kisumu_store =  EmbeddingStore.from_doc(\"kisumu_drawings_resized/image_embeddings/clip_image_embeddings_doc\")\n",
    "beijing_sanjose_store =  EmbeddingStore.from_doc(\"beijing_sanjose_drawings_resized/image_embeddings/clip_image_embeddings_doc\")\n",
    "text_embeddings = EmbeddingStore.from_doc(\"../data/embeddings/text_embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only choosing embeddings that include verbal cues and not picture cues and separating sanjose and Beijing\n",
    "sanjose_store = EmbeddingStore()\n",
    "beijing_store = EmbeddingStore()\n",
    "for embedding in beijing_sanjose_store.EmbeddingList:\n",
    "    # if this embedding is a verbal cue and not a picture cue\n",
    "    if \"S_\" in embedding.url:\n",
    "        if \"sanjose\" in embedding.url:\n",
    "            sanjose_store.add_embedding(embedding=embedding.embedding, url=embedding.url)\n",
    "        else:\n",
    "            beijing_store.add_embedding(embedding=embedding.embedding, url=embedding.url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kisumu embeddings: 1440\n",
      "Beijing embeddings: 736\n",
      "sanjose embeddings: 716\n",
      "newdelhi embeddings: 3983\n"
     ]
    }
   ],
   "source": [
    "print(f\"Kisumu embeddings: {len(kisumu_store.EmbeddingList)}\")\n",
    "print(f\"Beijing embeddings: {len(beijing_store.EmbeddingList)}\")\n",
    "print(f\"sanjose embeddings: {len(sanjose_store.EmbeddingList)}\")\n",
    "print(f\"newdelhi embeddings: {len(newdelhi_store.EmbeddingList)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract metadata about location, category and age from the file names and calculate probability of the correct category being chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from vislearnlabpy.embeddings.similarity_utils import calculate_probability\n",
    "\n",
    "def extract_beijing_metadata(url):\n",
    "    \"\"\"Extract metadata from Beijing URL format\"\"\"\n",
    "    filename = os.path.basename(url)\n",
    "    # Determine location\n",
    "    location = \"Beijing\" if \"THU\" in filename else \"sanjose\"\n",
    "    # Extract age\n",
    "    age_match = re.search(r'age(\\d+)', filename)\n",
    "    age = int(age_match.group(1)) if age_match else None\n",
    "    # Extract category (between first and second underscore, after the initial letter)\n",
    "    parts = filename.split('_')\n",
    "    category = parts[1] if len(parts) > 1 else None\n",
    "    # Extract participant ID (everything before .png)\n",
    "    participant_id = filename.replace('.png', '').split(\"_\")[-1]\n",
    "    return {\n",
    "        'location': location,\n",
    "        'age': age,\n",
    "        'category': category,\n",
    "        'participant_id': participant_id\n",
    "    }\n",
    "\n",
    "def extract_newdelhi_metadata(url):\n",
    "    filename = os.path.basename(url)\n",
    "    # remove leading articles\n",
    "    filename_clean = filename.removeprefix(\"a_\").removeprefix(\"an_\").removeprefix(\"three_\").removeprefix(\"two_\")\n",
    "    parts = filename_clean.split('_')\n",
    "    participant_id = parts[2].upper()\n",
    "    category = parts[0]\n",
    "    age = newdelhi_subject_data[newdelhi_subject_data[\"PID\"] == participant_id][\"Age\"].values[0]\n",
    "    return {\n",
    "        'location': 'newdelhi',\n",
    "        'age': age,\n",
    "        'category': category,\n",
    "        'participant_id': participant_id\n",
    "    }\n",
    "\n",
    "def extract_kisumu_metadata(url):\n",
    "    \"\"\"Extract metadata from Kisumu URL format\"\"\"\n",
    "    filename = os.path.basename(url)\n",
    "    \n",
    "    # Split on first underscore to get participant and rest\n",
    "    parts = filename.split('_', 1)\n",
    "    participant_id = parts[0]\n",
    "    \n",
    "    # Extract age and add 3\n",
    "    age_match = re.search(r'age(\\d+)', filename)\n",
    "    age = int(age_match.group(1)) + 3 if age_match else None\n",
    "    \n",
    "    # Extract category (between age and trial)\n",
    "    category_match = re.search(r'age\\d+_([^_]+)_trial', filename)\n",
    "    category = category_match.group(1) if category_match else None\n",
    "    category = \"bike\" if category == \"Bicycle\" else category\n",
    "    \n",
    "    return {\n",
    "        'location': 'Kisumu',\n",
    "        'age': age,\n",
    "        'category': category,\n",
    "        'participant_id': participant_id\n",
    "    }\n",
    "\n",
    "def _process_site(\n",
    "    text_embeddings,\n",
    "    docs,\n",
    "    extract_metadata_fn,\n",
    "    recognizability_fn,\n",
    "    results,\n",
    "):\n",
    "    \"\"\"Helper to process embeddings for a single site and extend `results`.\"\"\"\n",
    "    for doc in docs:\n",
    "        md = extract_metadata_fn(doc.url)\n",
    "        if md[\"category\"] and md[\"age\"] is not None:\n",
    "            results.append(\n",
    "                {\n",
    "                    \"location\": md[\"location\"],\n",
    "                    \"recognizability\": recognizability_fn(\n",
    "                        doc.embedding,\n",
    "                        text_embeddings,     \n",
    "                        md[\"category\"].lower()\n",
    "                    ),\n",
    "                    \"age\": md[\"age\"],\n",
    "                    \"participant_id\": md[\"participant_id\"],\n",
    "                    \"drawing_category\": md[\"category\"].lower(),\n",
    "                    \"url\": doc.url,\n",
    "                }\n",
    "            )\n",
    "\n",
    "def process_embeddings(text_embeddings, beijing_list, sanjose_list, kisumu_list, newdelhi_list):\n",
    "    \"\"\"Process all embeddings and create the final dataset.\"\"\"\n",
    "    results = []\n",
    "    # processing beijing\n",
    "    _process_site(\n",
    "        text_embeddings,\n",
    "        beijing_list, \n",
    "        extract_beijing_metadata, \n",
    "        calculate_probability,\n",
    "        results,\n",
    "    )\n",
    "    # processing kisumu\n",
    "    _process_site(\n",
    "        text_embeddings, \n",
    "        kisumu_list,\n",
    "        extract_kisumu_metadata,\n",
    "        calculate_probability,   \n",
    "        results,\n",
    "    )\n",
    "    # processing sanjose\n",
    "    _process_site(\n",
    "        text_embeddings, \n",
    "        sanjose_list,\n",
    "        extract_beijing_metadata,\n",
    "        calculate_probability,   \n",
    "        results,\n",
    "    )\n",
    "    # processing newdelhi\n",
    "    _process_site(\n",
    "        text_embeddings, \n",
    "        newdelhi_list,\n",
    "        extract_newdelhi_metadata,\n",
    "        calculate_probability,   \n",
    "        results,\n",
    "    )\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# Main processing function\n",
    "def create_drawing_analysis_csv(text_embeddings, beijing_list, sanjose_list, kisumu_list, newdelhi_list, output_file='drawing_analysis.csv'):\n",
    "    \"\"\"\n",
    "    Main function to process all embeddings and create CSV\n",
    "    \"\"\"\n",
    "    \n",
    "    # Process all embeddings\n",
    "    results = process_embeddings(text_embeddings, beijing_list, sanjose_list, kisumu_list, newdelhi_list)\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"Results saved to {output_file}\")\n",
    "    print(f\"Total drawings: {len(results)}\")\n",
    "    print(f\"Locations: {df['location'].value_counts().to_dict()}\")\n",
    "    print(f\"Age range: {df['age'].min()} - {df['age'].max()}\")\n",
    "    print(f\"Categories: {df['drawing_category'].value_counts().to_dict()}\")\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to drawing_analysis.csv\n",
      "Total drawings: 6875\n",
      "Locations: {'newdelhi': 3983, 'Kisumu': 1440, 'Beijing': 736, 'sanjose': 716}\n",
      "Age range: 4 - 11\n",
      "Categories: {'house': 397, 'tree': 390, 'watch': 377, 'cat': 372, 'bike': 369, 'cup': 369, 'car': 368, 'hat': 367, 'bird': 360, 'chair': 358, 'rabbit': 354, 'airplane': 352, 'lines': 279, 'circle': 140, 'line': 140, 'shapes': 139, 'square': 139, 'tutorial': 139, 'shape': 136, 'spoon': 114, 'face': 114, 'toothbrush': 113, 'man': 113, 'phone': 112, 'bus': 112, 'dog': 111, 'fish': 109, 'key': 109, 'woman': 108, 'eyeglasses': 108, 'train': 107}\n"
     ]
    }
   ],
   "source": [
    "recognizability_df = create_drawing_analysis_csv(text_embeddings.EmbeddingList, beijing_store.EmbeddingList, sanjose_store.EmbeddingList, kisumu_store.EmbeddingList, newdelhi_store.EmbeddingList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding in categories to the embedding stores now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map each URL to the row as a dictionary of fields\n",
    "url_to_fields = recognizability_df.set_index('url').to_dict(orient='index')\n",
    "\n",
    "# Assign fields in loop\n",
    "for store in [beijing_store, kisumu_store, sanjose_store, newdelhi_store]:\n",
    "    for embedding in store.EmbeddingList:\n",
    "        fields = url_to_fields.get(embedding.url, {})\n",
    "        embedding.text = fields.get('drawing_category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docarray import DocList\n",
    "from vislearnlabpy.embeddings.embedding_store import CLIPImageEmbedding\n",
    "full_embedding_store = EmbeddingStore()\n",
    "full_embedding_store.EmbeddingList = DocList[CLIPImageEmbedding](\n",
    "    sanjose_store.EmbeddingList + beijing_store.EmbeddingList + kisumu_store.EmbeddingList + newdelhi_store.EmbeddingList\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to figure out url storing..\n",
    "# recognizability_df['id'] = recognizability_df['url'].apply(lambda p: Path(p).name)\n",
    "#for store in [beijing_store, kisumu_store, sanjose_store, newdelhi_store,full_embedding_store]:\n",
    "#    store.EmbeddingList.url = list(map(lambda p: Path(p).name, store.EmbeddingList.url))\n",
    "#os.makedirs(output_embedding_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file:///Users/visuallearninglab/Documents/kenya_draw/analysis/../data/embeddings/text_embeddings.doc'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# saving embedding files\n",
    "output_embedding_dir = \"../data/embeddings\"\n",
    "beijing_store.to_doc(f\"{output_embedding_dir}/beijing_store.doc\")\n",
    "kisumu_store.to_doc(f\"{output_embedding_dir}/kisumu_store.doc\")\n",
    "sanjose_store.to_doc(f\"{output_embedding_dir}/sanjose_store.doc\")\n",
    "newdelhi_store.to_doc(f\"{output_embedding_dir}/newdelhi_store.doc\")\n",
    "full_embedding_store.to_doc(f\"{output_embedding_dir}/full_embedding_store.doc\")\n",
    "text_embeddings.to_doc(f\"{output_embedding_dir}/text_embeddings.doc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "todo: port everything below this to a different file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating centroid distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Beijing' 'Kisumu' 'sanjose' 'newdelhi']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from vislearnlabpy.embeddings.similarity_utils import cosine_sim\n",
    "from vislearnlabpy.embeddings.utils import zscore_embeddings\n",
    "from docarray.utils.filter import filter_docs\n",
    "\n",
    "def calculate_centroid_distances(df, kisumu_store, beijing_store, sanjose_store, newdelhi_store):\n",
    "    \"\"\"\n",
    "    Calculate centroid embeddings for each age-location-category combination and compute distances.\n",
    "    Returns:\n",
    "    df: Original dataframe with added 'distance' column\n",
    "    \"\"\"\n",
    "    \n",
    "    # Helper function to get embedding list based on location\n",
    "    def get_embedding_list(location):\n",
    "        location_lower = location.lower()\n",
    "        if 'kisumu' in location_lower:\n",
    "            return kisumu_store.EmbeddingList\n",
    "        elif 'beijing' in location_lower:\n",
    "            return beijing_store.EmbeddingList\n",
    "        elif 'sanjose' in location_lower:\n",
    "            return sanjose_store.EmbeddingList\n",
    "        elif 'newdelhi' in location_lower:\n",
    "            return newdelhi_store.EmbeddingList\n",
    "        else:\n",
    "            return {}\n",
    "    \n",
    "    # Helper function to extract embedding from store\n",
    "    def get_embedding(url, embedding_list):\n",
    "        matches = filter_docs(embedding_list, {'url': {'$eq': url}})\n",
    "        embedding = matches[0].embedding if matches else None\n",
    "        return embedding\n",
    "    \n",
    "    # Group by age and location to calculate centroids\n",
    "    centroids = {}\n",
    "    centroid_urls = {}\n",
    "    for (age, location, category), group in df.groupby(['age', 'location', 'drawing_category']):\n",
    "        embedding_list = get_embedding_list(location)\n",
    "        embeddings = []\n",
    "        urls = []\n",
    "        # Collect all embeddings for this age-location combination\n",
    "        for url in group['url']:\n",
    "            embedding = get_embedding(url, embedding_list)\n",
    "            if embedding is not None:\n",
    "                embeddings.append(np.array(embedding))\n",
    "                urls.append(url)\n",
    "        \n",
    "        # Calculate centroid if we have embeddings\n",
    "        if embeddings:\n",
    "            centroid = np.mean(embeddings, axis=0)\n",
    "            centroids[(age, location, category)] = centroid\n",
    "            \n",
    "            # Find the URL with embedding closest to the centroid\n",
    "            min_distance = float('inf')\n",
    "            closest_url = None\n",
    "            closest_embedding = None\n",
    "            \n",
    "            for url, embedding in zip(urls, embeddings):\n",
    "                distance = np.linalg.norm(embedding - centroid)\n",
    "                if distance < min_distance:\n",
    "                    min_distance = distance\n",
    "                    closest_url = url\n",
    "                    closest_embedding = embedding\n",
    "            \n",
    "            centroid_urls[(age, location, category)] = {\n",
    "                'url': closest_url,\n",
    "                'embedding': closest_embedding\n",
    "            }\n",
    "        else:\n",
    "            print(f\"Warning: No embeddings found for age={age}, category={category}, location={location}\")\n",
    "            centroids[(age, location, category)] = None\n",
    "    all_locations = df['location'].unique()\n",
    "    print(all_locations)\n",
    "    # Calculate distances for each row in the dataframe\n",
    "    distances = []\n",
    "    distances_euclidean = []\n",
    "    # Initialize dictionaries to store distances for each location\n",
    "    location_distances = {}\n",
    "    location_distances_euclidean = {}\n",
    "\n",
    "    # Initialize distance lists for each location in all_locations\n",
    "    for location in all_locations:\n",
    "        location_distances[location] = []\n",
    "        location_distances_euclidean[location] = []\n",
    "        '''\n",
    "        some zscoring logic which doesn't actually make sense to do here\n",
    "        keys, embeddings = zip(*[\n",
    "            ((age, loc, cat), emb)\n",
    "            for (age, loc, cat), emb in centroids.items()\n",
    "            if loc == location\n",
    "        ])\n",
    "\n",
    "        stacked = np.stack(embeddings)\n",
    "        zscored = zscore_embeddings(stacked)\n",
    "\n",
    "        for key, z_emb in zip(keys, zscored):\n",
    "            centroids[key] = z_emb\n",
    "        '''\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        age = row['age']\n",
    "        location = row['location']\n",
    "        category = row['drawing_category']\n",
    "        url = row['url']\n",
    "        # Get the centroid for this age-location combination\n",
    "        centroid = centroids.get((age, location, category))\n",
    "        if centroid is None:\n",
    "            distances.append(np.nan)\n",
    "            continue\n",
    "        # Get the embedding for this specific URL\n",
    "        embedding_list = get_embedding_list(location)\n",
    "        embedding = get_embedding(url, embedding_list)\n",
    "        \n",
    "        if embedding is None:\n",
    "            distances.append(np.nan)\n",
    "            continue\n",
    "        \n",
    "        embedding = np.stack(embedding)\n",
    "        # Cosine distance calculation\n",
    "        distance = 1 - cosine_sim(embedding, np.stack(centroid))\n",
    "        distance_euclidean = np.linalg.norm(embedding - centroid)\n",
    "        distances_euclidean.append(distance_euclidean)\n",
    "        distances.append(distance)\n",
    "\n",
    "        for target_location in all_locations:\n",
    "            # Get centroid for the target location\n",
    "            target_centroid = centroids.get((age, target_location, category))\n",
    "        \n",
    "            if target_centroid is None:\n",
    "                location_distances[target_location].append(np.nan)\n",
    "                location_distances_euclidean[target_location].append(np.nan)\n",
    "            else:\n",
    "                # Calculate cosine distance to target location centroid\n",
    "                target_distance = 1 - cosine_sim(embedding, np.stack(target_centroid))\n",
    "                target_distance_euclidean = np.linalg.norm(embedding - np.stack(target_centroid))\n",
    "\n",
    "                location_distances[target_location].append(target_distance)\n",
    "                location_distances_euclidean[target_location].append(target_distance_euclidean)\n",
    "\n",
    "    \n",
    "    df_result = df.copy()\n",
    "    df_result['distance'] = distances\n",
    "    df_result['distance_euclidean'] = distances_euclidean\n",
    "    for location in all_locations:\n",
    "        df_result[f'distance_{location}'] = location_distances[location]\n",
    "        df_result[f'distance_euclidean_{location}'] = location_distances_euclidean[location]\n",
    "\n",
    "    return df_result, centroids, centroid_urls\n",
    "\n",
    "\n",
    "df_with_recognizability_distances, output_centroids, output_centroid_urls = calculate_centroid_distances(recognizability_df, kisumu_store, beijing_store, sanjose_store, newdelhi_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_recognizability_distances.drop(columns=['url']).to_csv(\"../data/clip_recognizability_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_categories = [\"airplane\", \"bike\", \"bird\", \"hat\", \"rabbit\", \"watch\",\n",
    "                       \"cat\", \"house\", \"cup\", \"chair\", \"tree\", \"car\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing airplane...\n",
      "  Running t-SNE for airplane...\n",
      "  Saved visualization for airplane\n",
      "Processing bike...\n",
      "  Running t-SNE for bike...\n",
      "  Saved visualization for bike\n",
      "Processing bird...\n",
      "  Running t-SNE for bird...\n",
      "  Saved visualization for bird\n",
      "Processing hat...\n",
      "  Running t-SNE for hat...\n",
      "  Saved visualization for hat\n",
      "Processing rabbit...\n",
      "  Running t-SNE for rabbit...\n",
      "  Saved visualization for rabbit\n",
      "Processing watch...\n",
      "  Running t-SNE for watch...\n",
      "  Saved visualization for watch\n",
      "Processing cat...\n",
      "  Running t-SNE for cat...\n",
      "  Saved visualization for cat\n",
      "Processing house...\n",
      "  Running t-SNE for house...\n",
      "  Saved visualization for house\n",
      "Processing cup...\n",
      "  Running t-SNE for cup...\n",
      "  Saved visualization for cup\n",
      "Processing chair...\n",
      "  Running t-SNE for chair...\n",
      "  Saved visualization for chair\n",
      "Processing tree...\n",
      "  Running t-SNE for tree...\n",
      "  Saved visualization for tree\n",
      "Processing car...\n",
      "  Running t-SNE for car...\n",
      "  Saved visualization for car\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import RANSACRegressor, LinearRegression\n",
    "from PIL import Image\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "from pathlib import Path\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# Toggle between direct connection and RANSAC regression\n",
    "USE_RANSAC = False  # Set to True for RANSAC regression, False for direct connection\n",
    "\n",
    "paths = {\n",
    "    'Beijing': beijing_dir,\n",
    "    'sanjose': beijing_dir,\n",
    "    'newdelhi': newdelhi_dir,\n",
    "    'Kisumu': kisumu_cropped_drawings_path\n",
    "}\n",
    "\n",
    "centroids_dict = output_centroids\n",
    "centroid_urls_dict = output_centroid_urls\n",
    "\n",
    "# Convert your dict_keys and dict_values to lists if needed\n",
    "centroids_keys = list(centroids_dict.keys())\n",
    "centroids_values = list(centroids_dict.values())\n",
    "\n",
    "# Create initial DataFrame with all data\n",
    "df_all = pd.DataFrame({\n",
    "    'age': [k[0] for k in centroids_keys],\n",
    "    'location': [k[1] for k in centroids_keys],\n",
    "    'category': [k[2] for k in centroids_keys],\n",
    "    'embedding': centroids_values,\n",
    "    'url': [centroid_urls_dict[k]['url'] if centroid_urls_dict[k] is not None else None for k in centroids_keys]\n",
    "})\n",
    "\n",
    "# Filter for specific categories and ages\n",
    "selected_categories = [\"airplane\", \"bike\", \"bird\", \"hat\", \"rabbit\", \"watch\",\n",
    "                       \"cat\", \"house\", \"cup\", \"chair\", \"tree\", \"car\"]\n",
    "df_all = df_all[df_all['category'].isin(selected_categories)]\n",
    "df_all = df_all[(df_all['age'] >= 4) & (df_all['age'] <= 9)]\n",
    "\n",
    "# Get unique locations\n",
    "locations = sorted(df_all['location'].unique())\n",
    "\n",
    "# Define base colors for each location\n",
    "base_colors = {\n",
    "    'Kisumu': '#1f77b4', 'Beijing': '#ff7f0e', 'sanjose': '#2ca02c', 'newdelhi': '#d62728'\n",
    "}\n",
    "\n",
    "location_base_colors = {loc: base_colors.get(loc, f'C{i}') for i, loc in enumerate(locations)}\n",
    "\n",
    "# Function to adjust color brightness based on age\n",
    "def get_age_color(base_color, age, min_age=4, max_age=9):\n",
    "    \"\"\"\n",
    "    Adjust color brightness based on age.\n",
    "    Younger ages (4) -> brighter\n",
    "    Older ages (9) -> darker\n",
    "    \"\"\"\n",
    "    # Normalize age to 0-1 range\n",
    "    age_norm = (age - min_age) / (max_age - min_age)\n",
    "    \n",
    "    # Convert hex to RGB\n",
    "    rgb = mcolors.to_rgb(base_color)\n",
    "    \n",
    "    # Adjust brightness: younger = brighter (closer to white), older = darker (closer to base color)\n",
    "    # brightness_factor ranges from 1.8 (brightest, age 4) to 0.6 (darkest, age 9)\n",
    "    brightness_factor = 1.8 - (age_norm * 1.2)\n",
    "    \n",
    "    # Apply brightness\n",
    "    adjusted_rgb = tuple(min(1.0, c * brightness_factor) for c in rgb)\n",
    "    \n",
    "    return adjusted_rgb\n",
    "\n",
    "# Function to load and prepare image with consistent size\n",
    "def load_image(url, location, target_size=80):\n",
    "    \"\"\"Load image from url with proper path prepending and resize to consistent size\"\"\"\n",
    "    try:\n",
    "        if location == \"newdelhi\":\n",
    "            location_path = Path(paths[location]) / str(url).split(\"_sketch\")[0]\n",
    "        else:\n",
    "            location_path = Path(paths[location])\n",
    "        full_path = location_path / str(url)\n",
    "\n",
    "        img = Image.open(full_path).convert(\"RGBA\")\n",
    "        img.thumbnail((target_size, target_size), Image.Resampling.LANCZOS)\n",
    "\n",
    "        # Create white background and paste RGBA image onto it\n",
    "        background = Image.new(\"RGB\", img.size, (255, 255, 255))\n",
    "        background.paste(img, mask=img.split()[3])  # 3 = alpha channel\n",
    "\n",
    "        return OffsetImage(background, zoom=1.0)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Create separate plot for each category with its own t-SNE\n",
    "for category in selected_categories:\n",
    "    print(f\"Processing {category}...\")\n",
    "    \n",
    "    # Filter data for this category only\n",
    "    category_df = df_all[df_all['category'] == category].copy()\n",
    "    \n",
    "    if len(category_df) == 0:\n",
    "        print(f\"No data for {category}, skipping...\")\n",
    "        continue\n",
    "    \n",
    "    # Stack embeddings for this category only\n",
    "    embeddings_matrix = np.vstack(category_df['embedding'].values)\n",
    "    \n",
    "    # Run t-SNE on this category's embeddings only\n",
    "    print(f\"  Running t-SNE for {category}...\")\n",
    "    tsne = TSNE(n_components=2, random_state=42, perplexity=min(3, len(embeddings_matrix)-1))\n",
    "    embeddings_2d = tsne.fit_transform(embeddings_matrix)\n",
    "    \n",
    "    # Add t-SNE coordinates to dataframe\n",
    "    category_df['x'] = embeddings_2d[:, 0]\n",
    "    category_df['y'] = embeddings_2d[:, 1]\n",
    "    \n",
    "    # Create plot\n",
    "    fig, ax = plt.subplots(figsize=(20, 16))\n",
    "    \n",
    "    # First pass: Plot points and images (lower z-order)\n",
    "    for location in locations:\n",
    "        loc_data = category_df[category_df['location'] == location].sort_values('age')\n",
    "        \n",
    "        if len(loc_data) >= 1:\n",
    "            # Plot points for each age with brightness-based coloring\n",
    "            for _, row in loc_data.iterrows():\n",
    "                age_color = location_base_colors[location] #get_age_color(location_base_colors[location], row['age'])\n",
    "                \n",
    "                ax.scatter(row['x'], row['y'], \n",
    "                          color=age_color, \n",
    "                          s=400,\n",
    "                          alpha=0.8,\n",
    "                          edgecolors='white',\n",
    "                          linewidths=2,\n",
    "                          zorder=3)\n",
    "                \n",
    "                ax.annotate(f\"{int(row['age'])}\", \n",
    "                           (row['x'], row['y']), \n",
    "                           fontsize=14, \n",
    "                           ha='center', \n",
    "                           va='center',\n",
    "                           color='white',\n",
    "                           weight='bold',\n",
    "                           zorder=4)\n",
    "                \n",
    "                if row['url'] is not None:\n",
    "                    img = load_image(row['url'], row['location'], target_size=60)\n",
    "                    if img is not None:\n",
    "                        ab = AnnotationBbox(img, (row['x'], row['y']),\n",
    "                                          xybox=(0, -55),\n",
    "                                          xycoords='data',\n",
    "                                          boxcoords='offset points',\n",
    "                                          frameon=True,\n",
    "                                          pad=0.3,\n",
    "                                          bboxprops=dict(edgecolor=age_color,\n",
    "                                                        facecolor='white',\n",
    "                                                        linewidth=2))\n",
    "                        ax.add_artist(ab)\n",
    "    \n",
    "    # Second pass: Draw arrows on top (higher z-order)\n",
    "    for location in locations:\n",
    "        loc_data = category_df[category_df['location'] == location].sort_values('age')\n",
    "        \n",
    "        if len(loc_data) > 1:\n",
    "            if USE_RANSAC:\n",
    "                # RANSAC regression approach\n",
    "                X = loc_data['age'].values.reshape(-1, 1)\n",
    "                y_x = loc_data['x'].values\n",
    "                y_y = loc_data['y'].values\n",
    "\n",
    "                model_x = RANSACRegressor(LinearRegression()).fit(X, y_x)\n",
    "                model_y = RANSACRegressor(LinearRegression()).fit(X, y_y)\n",
    "\n",
    "                age_start, age_end = X.min(), X.max()\n",
    "                x_start, x_end = model_x.predict([[age_start]])[0], model_x.predict([[age_end]])[0]\n",
    "                y_start, y_end = model_y.predict([[age_start]])[0], model_y.predict([[age_end]])[0]\n",
    "            else:\n",
    "                # Direct connection from lowest to highest age\n",
    "                youngest = loc_data.iloc[0]  # Already sorted by age\n",
    "                oldest = loc_data.iloc[-1]\n",
    "                \n",
    "                x_start, y_start = youngest['x'], youngest['y']\n",
    "                x_end, y_end = oldest['x'], oldest['y']\n",
    "\n",
    "            arrow = ax.annotate(\n",
    "                '', xy=(x_end, y_end), xytext=(x_start+1, y_start+1),\n",
    "                arrowprops=dict(arrowstyle='->',\n",
    "                                color=location_base_colors[location],\n",
    "                                alpha=0.7,\n",
    "                                linewidth=5,\n",
    "                                mutation_scale=35),\n",
    "                zorder=10  # High z-order to place arrows on top\n",
    "            )\n",
    "    \n",
    "    ax.set_title(f'{category}', fontsize=22, fontweight='bold', pad=20)\n",
    "    ax.set_xlabel('t-SNE 1', fontsize=14)\n",
    "    ax.set_ylabel('t-SNE 2', fontsize=14)\n",
    "    \n",
    "    # Create custom legend for locations\n",
    "    location_handles = []\n",
    "    for location in locations:\n",
    "        location_handles.append(plt.Line2D([0], [0], marker='o', color='w', \n",
    "                                          markerfacecolor=location_base_colors[location], \n",
    "                                          markersize=10, label=location,\n",
    "                                          markeredgecolor='white', markeredgewidth=1.5))\n",
    "    \n",
    "    # Add legend to plot\n",
    "    legend = ax.legend(handles=location_handles, loc='upper left', \n",
    "                       fontsize=12, title='Location', title_fontsize=13)\n",
    "    \n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'tsne_plots/tsne_centroid_{category}_age.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"  Saved visualization for {category}\")\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from collections import defaultdict\n",
    "from vislearnlabpy.embeddings.similarity_utils import cosine_sim\n",
    "from vislearnlabpy.embeddings.utils import zscore_embeddings\n",
    "from docarray.utils.filter import filter_docs\n",
    "import seaborn as sns\n",
    "\n",
    "def collect_all_embeddings(df, kisumu_store, beijing_store, sanjose_store, newdelhi_store):\n",
    "    \"\"\"\n",
    "    Collect all embeddings from the dataframe with their metadata.\n",
    "    Returns a dataframe with embeddings and metadata.\n",
    "    \"\"\"\n",
    "    def get_embedding_list(location):\n",
    "        location_lower = location.lower()\n",
    "        if 'kisumu' in location_lower:\n",
    "            return kisumu_store.EmbeddingList\n",
    "        elif 'beijing' in location_lower:\n",
    "            return beijing_store.EmbeddingList\n",
    "        elif 'sanjose' in location_lower:\n",
    "            return sanjose_store.EmbeddingList\n",
    "        elif 'newdelhi' in location_lower:\n",
    "            return newdelhi_store.EmbeddingList\n",
    "        else:\n",
    "            return {}\n",
    "    \n",
    "    def get_embedding(url, embedding_list):\n",
    "        matches = filter_docs(embedding_list, {'url': {'$eq': url}})\n",
    "        embedding = matches[0].embedding if matches else None\n",
    "        return embedding\n",
    "    \n",
    "    embeddings_data = []\n",
    "    for _, row in df.iterrows():\n",
    "        embedding_list = get_embedding_list(row['location'])\n",
    "        embedding = get_embedding(row['url'], embedding_list)\n",
    "        \n",
    "        if embedding is not None:\n",
    "            embeddings_data.append({\n",
    "                'embedding': np.array(embedding),\n",
    "                'age': row['age'],\n",
    "                'location': row['location'],\n",
    "                'category': row['drawing_category'],\n",
    "                'url': row['url']\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(embeddings_data)\n",
    "\n",
    "\n",
    "def create_tsne_per_category(df, stores_dict, centroid_urls, emb_df, output_dir='tsne_plots', perplexity=30, random_state=42):\n",
    "    \"\"\"\n",
    "    Type 1: Create t-SNE plots per category with all embeddings.\n",
    "    Color by location, brightness by age (no age labels).\n",
    "    Includes images of closest embeddings to centroids.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with columns ['age', 'location', 'drawing_category', 'url']\n",
    "        stores_dict: Dict with keys ['kisumu', 'beijing', 'sanjose', 'newdelhi'] mapping to stores\n",
    "        centroid_urls: Dict from calculate_centroid_distances containing closest URLs and embeddings\n",
    "        output_dir: Directory to save plots\n",
    "    \"\"\"\n",
    "    import os\n",
    "    from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "    from PIL import Image\n",
    "    import requests\n",
    "    from io import BytesIO\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Define animal categories\n",
    "    animal_categories = ['bird', 'rabbit', 'cat']\n",
    "    \n",
    "    # Get unique categories\n",
    "    categories = selected_categories\n",
    "    \n",
    "    # Color palette for locations\n",
    "    location_colors = {'Kisumu': '#1f77b4', 'Beijing': '#ff7f0e', 'sanjose': '#2ca02c', 'newdelhi': '#d62728'}\n",
    "    \n",
    "    for category in categories:\n",
    "        print(f\"Processing {category}...\")\n",
    "        cat_data = emb_df[emb_df['category'] == category].copy()\n",
    "        \n",
    "        if len(cat_data) < 2:\n",
    "            print(f\"Skipping {category} - not enough data\")\n",
    "            continue\n",
    "        \n",
    "        # Extract embeddings\n",
    "        embeddings = np.stack(cat_data['embedding'].values)\n",
    "        \n",
    "        # Run t-SNE\n",
    "        print(f\"Running t-SNE for {category}...\")\n",
    "        tsne = TSNE(n_components=2, perplexity=min(perplexity, len(embeddings)-1), \n",
    "                    random_state=random_state)\n",
    "        tsne_results = tsne.fit_transform(embeddings)\n",
    "        \n",
    "        # Create mapping from URL to t-SNE coordinates\n",
    "        cat_data_reset = cat_data.reset_index(drop=True)\n",
    "        url_to_tsne = {}\n",
    "        for idx, row in cat_data_reset.iterrows():\n",
    "            url_to_tsne[row['url']] = tsne_results[idx]\n",
    "        \n",
    "        # Normalize age for brightness (0 to 1) - discrete values 4-9\n",
    "        # Map age 4 -> 0.0 (dimmest), age 9 -> 1.0 (brightest)\n",
    "        age_normalized = (cat_data['age'] - 4) / (9 - 4)\n",
    "        \n",
    "        # Create plot\n",
    "        fig, ax = plt.subplots(figsize=(12, 10))\n",
    "        \n",
    "        for location in cat_data['location'].unique():\n",
    "            loc_mask = cat_data['location'] == location\n",
    "            loc_data = cat_data[loc_mask]\n",
    "            loc_tsne = tsne_results[loc_mask]\n",
    "            loc_age_norm = age_normalized[loc_mask]\n",
    "            \n",
    "            # Use age for alpha (brightness)\n",
    "            alphas = 0.1 + 0.9 * loc_age_norm  # Range from 0.1 to 1.0\n",
    "\n",
    "            for i, (x, y, alpha) in enumerate(zip(loc_tsne[:, 0], loc_tsne[:, 1], alphas)):\n",
    "                ax.scatter(x, y, c=[location_colors.get(location, '#000000')], \n",
    "                          alpha=alpha, s=100, edgecolors='white', linewidth=0.5)\n",
    "        \n",
    "        # Add centroid images\n",
    "        for (age, location, cat), centroid_info in centroid_urls.items():\n",
    "            if cat == category:\n",
    "                centroid_url = centroid_info['url']\n",
    "                \n",
    "                # Find the t-SNE coordinates for this URL\n",
    "                if centroid_url in url_to_tsne:\n",
    "                    x, y = url_to_tsne[centroid_url]\n",
    "                    \n",
    "                    # Calculate alpha for this centroid based on age\n",
    "                    centroid_alpha = 0.1 + 0.9 * ((age - 4) / (9 - 4))\n",
    "                    \n",
    "                    try:\n",
    "                        # Load image from URL\n",
    "                        img = load_image(centroid_url, location, target_size=40)\n",
    "                        \n",
    "                        ab = AnnotationBbox(img, (x, y),\n",
    "                                          frameon=True,\n",
    "                                          pad=0.3,\n",
    "                                          boxcoords=\"data\",\n",
    "                                          box_alignment=(0.5, 0.5),\n",
    "                                          bboxprops=dict(edgecolor=location_colors.get(location, '#000000'),\n",
    "                                                        alpha=centroid_alpha,\n",
    "                                                        facecolor='white',\n",
    "                                                        linewidth=2))\n",
    "                        ax.add_artist(ab)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Could not load image for {centroid_url}: {e}\")\n",
    "        \n",
    "        ax.set_title(f't-SNE: {category.capitalize()} (colored by location, brightness by age)', fontsize=16)\n",
    "        ax.set_xlabel('t-SNE Component 1', fontsize=12)\n",
    "        ax.set_ylabel('t-SNE Component 2', fontsize=12)\n",
    "        \n",
    "        # Create legend for locations\n",
    "        from matplotlib.patches import Patch\n",
    "        legend_elements = [Patch(facecolor=color, label=loc) \n",
    "                          for loc, color in location_colors.items() if loc in cat_data['location'].values]\n",
    "        ax.legend(handles=legend_elements, title='Location', loc='best')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{output_dir}/tsne_category_{category}.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"Saved visualization for {category}\")\n",
    "\n",
    "def create_tsne_per_age(df, stores_dict, emb_df, output_dir='tsne_plots', perplexity=30, random_state=42):\n",
    "    \"\"\"\n",
    "    Type 2: Create t-SNE plots per age bin, separating animals and non-animals.\n",
    "    Color by category.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with columns ['age', 'location', 'drawing_category', 'url']\n",
    "        stores_dict: Dict with keys ['kisumu', 'beijing', 'sanjose', 'newdelhi'] mapping to stores\n",
    "        output_dir: Directory to save plots\n",
    "    \"\"\"\n",
    "    import os\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Collect all embeddings\n",
    "    \n",
    "    # Get unique ages\n",
    "    ages = sorted(emb_df['age'].unique())\n",
    "    \n",
    "    for age in ages:\n",
    "        age_data = emb_df[emb_df['age'] == age].copy()\n",
    "        \n",
    "        # Process animals and non-animals separately\n",
    "        #for is_animal, label in [(True, 'animals'), (False, 'non_animals')]:\n",
    "        #subset = age_data[age_data['is_animal'] == is_animal].copy()\n",
    "        \n",
    "        if len(age_data) < 2:\n",
    "            print(f\"Skipping age {age} - not enough data\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"Processing age {age}...\")\n",
    "        \n",
    "        # Extract embeddings\n",
    "        embeddings = np.stack(age_data['embedding'].values)\n",
    "        \n",
    "        # Run t-SNE\n",
    "        print(f\"Running t-SNE for age {age}...\")\n",
    "        tsne = TSNE(n_components=2, perplexity=min(perplexity, len(embeddings)-1), \n",
    "                    random_state=random_state)\n",
    "        tsne_results = tsne.fit_transform(embeddings)\n",
    "        \n",
    "        # Create plot\n",
    "        fig, ax = plt.subplots(figsize=(12, 10))\n",
    "        \n",
    "        # Get unique categories and assign colors\n",
    "        categories = age_data['category'].unique()\n",
    "        colors = sns.color_palette('husl', n_colors=len(categories))\n",
    "        color_map = dict(zip(categories, colors))\n",
    "        \n",
    "        for category in categories:\n",
    "            cat_mask = age_data['category'] == category\n",
    "            cat_tsne = tsne_results[cat_mask]\n",
    "            \n",
    "            ax.scatter(cat_tsne[:, 0], cat_tsne[:, 1], \n",
    "                        c=[color_map[category]], label=category.capitalize(),\n",
    "                        alpha=0.7, s=100, edgecolors='white', linewidth=0.5)\n",
    "        \n",
    "        ax.set_title(f't-SNE: Age {age}', fontsize=16)\n",
    "        ax.set_xlabel('t-SNE Component 1', fontsize=12)\n",
    "        ax.set_ylabel('t-SNE Component 2', fontsize=12)\n",
    "        ax.legend(title='Category', loc='best', ncol=2)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{output_dir}/tsne_age_{age}.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"Saved visualization for age {age}\")\n",
    "\n",
    "\n",
    "def create_tsne_all_embeddings(df, stores_dict, emb_df, output_dir='tsne_plots', perplexity=50, random_state=42):\n",
    "    \"\"\"\n",
    "    Type 3: Create t-SNE plot with all embeddings.\n",
    "    Color by whether animal/non-animal category, brightness by age.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with columns ['age', 'location', 'drawing_category', 'url']\n",
    "        stores_dict: Dict with keys ['kisumu', 'beijing', 'sanjose', 'newdelhi'] mapping to stores\n",
    "        output_dir: Directory to save plots\n",
    "    \"\"\"\n",
    "    import os\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Define animal categories\n",
    "    animal_categories = ['bird', 'rabbit', 'cat']\n",
    "    emb_df['is_animal'] = emb_df['category'].isin(animal_categories)\n",
    "    \n",
    "    # Extract embeddings\n",
    "    embeddings = np.stack(emb_df['embedding'].values)\n",
    "    \n",
    "    # Run t-SNE\n",
    "    print(\"Running t-SNE for all embeddings...\")\n",
    "    tsne = TSNE(n_components=2, perplexity=min(perplexity, len(embeddings)-1), \n",
    "                random_state=random_state)\n",
    "    tsne_results = tsne.fit_transform(embeddings)\n",
    "    \n",
    "    # Normalize age for brightness\n",
    "    age_normalized = (emb_df['age'] - emb_df['age'].min()) / (emb_df['age'].max() - emb_df['age'].min())\n",
    "    \n",
    "    # Create plot\n",
    "    fig, ax = plt.subplots(figsize=(14, 12))\n",
    "    \n",
    "    # Get unique categories and assign colors\n",
    "    categories = emb_df['category'].unique()\n",
    "    colors = sns.color_palette('husl', n_colors=len(categories))\n",
    "    color_map = dict(zip(categories, colors))\n",
    "    \n",
    "    for category in categories:\n",
    "        cat_mask = emb_df['category'] == category\n",
    "        cat_data = emb_df[cat_mask]\n",
    "        cat_tsne = tsne_results[cat_mask]\n",
    "        cat_age_norm = age_normalized[cat_mask]\n",
    "        \n",
    "        # Use age for alpha\n",
    "        alphas = 0.3 + 0.7 * cat_age_norm\n",
    "        \n",
    "        for i, (x, y, alpha) in enumerate(zip(cat_tsne[:, 0], cat_tsne[:, 1], alphas)):\n",
    "            ax.scatter(x, y, c=[color_map[category]], \n",
    "                      alpha=alpha, s=80, edgecolors='white', linewidth=0.3,\n",
    "                      label=category.capitalize() if i == 0 else '')\n",
    "    \n",
    "    # Remove duplicate labels\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    by_label = dict(zip(labels, handles))\n",
    "    ax.legend(by_label.values(), by_label.keys(), title='Category', \n",
    "             loc='best', ncol=3, fontsize=10)\n",
    "    \n",
    "    ax.set_title('t-SNE: All Embeddings (colored by category, brightness by age)', fontsize=16)\n",
    "    ax.set_xlabel('t-SNE Component 1', fontsize=12)\n",
    "    ax.set_ylabel('t-SNE Component 2', fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_dir}/tsne_all_embeddings.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"Saved visualization for all embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ages: [np.int64(4), np.int64(5), np.int64(6), np.int64(7), np.int64(8), np.int64(9), np.int64(10), np.int64(11)]\n",
      "Locations: ['Beijing', 'Kisumu', 'newdelhi', 'sanjose']\n",
      "Categories: ['bird', 'rabbit', 'cat', 'airplane', 'car', 'bike', 'hat', 'watch', 'house', 'cup', 'chair', 'tree']\n",
      "Saved RDM by age\n",
      "Saved RDM by category\n",
      "Saved simplified category RDM\n",
      "Saved RDM for age 4\n",
      "Saved RDM for age 5\n",
      "Saved RDM for age 6\n",
      "Saved RDM for age 7\n",
      "Saved RDM for age 8\n",
      "Saved RDM for age 9\n",
      "Saved simplified category RDM for age 4\n",
      "Saved simplified category RDM for age 5\n",
      "Saved simplified category RDM for age 6\n",
      "Saved simplified category RDM for age 7\n",
      "Saved simplified category RDM for age 8\n",
      "Saved simplified category RDM for age 9\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.spatial.distance import cosine\n",
    "import pandas as pd\n",
    "\n",
    "def create_rdm_from_centroids(output_centroids, metric='cosine'):\n",
    "    \"\"\"\n",
    "    Create RDMs (Representational Dissimilarity Matrices) from centroid embeddings.\n",
    "    \n",
    "    Creates two RDMs:\n",
    "    1. Average similarity across all categories for each age\n",
    "    2. Average similarity across ages for each category\n",
    "    \n",
    "    Args:\n",
    "        output_centroids: Dictionary from calculate_centroid_distances with keys (age, location, category)\n",
    "        metric: Distance metric to use ('cosine' or 'euclidean')\n",
    "    \n",
    "    Returns:\n",
    "        rdm_by_age: RDM averaged across categories for each age\n",
    "        rdm_by_category: RDM averaged across ages for each category\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define category order: animals first, then non-animals\n",
    "    category_order = [\"bird\", \"rabbit\", \"cat\", \"airplane\", \"car\", \"bike\", \"hat\", \n",
    "                      \"watch\", \"house\", \"cup\", \"chair\", \"tree\"]\n",
    "    \n",
    "    # Extract unique ages and locations\n",
    "    ages = sorted(list(set([k[0] for k in output_centroids.keys() if output_centroids[k] is not None])))\n",
    "    locations = sorted(list(set([k[1] for k in output_centroids.keys() if output_centroids[k] is not None])))\n",
    "    \n",
    "    # Filter category_order to only include categories present in the data\n",
    "    available_categories = set([k[2] for k in output_centroids.keys() if output_centroids[k] is not None])\n",
    "    categories = [c for c in category_order if c in available_categories]\n",
    "    \n",
    "    print(f\"Ages: {ages}\")\n",
    "    print(f\"Locations: {locations}\")\n",
    "    print(f\"Categories: {categories}\")\n",
    "    \n",
    "    # ===== RDM 1: Average across categories for each age =====\n",
    "    # Create matrix: rows and columns are (age, location) pairs\n",
    "    age_location_pairs = [(age, loc) for age in ages for loc in locations]\n",
    "    n_pairs = len(age_location_pairs)\n",
    "    \n",
    "    rdm_by_age = np.zeros((n_pairs, n_pairs))\n",
    "    count_matrix_age = np.zeros((n_pairs, n_pairs))  # Track how many categories contributed\n",
    "    \n",
    "    for i, (age1, loc1) in enumerate(age_location_pairs):\n",
    "        for j, (age2, loc2) in enumerate(age_location_pairs):\n",
    "            distances = []\n",
    "            \n",
    "            # Average across all categories\n",
    "            for category in categories:\n",
    "                centroid1 = output_centroids.get((age1, loc1, category))\n",
    "                centroid2 = output_centroids.get((age2, loc2, category))\n",
    "                \n",
    "                if centroid1 is not None and centroid2 is not None:\n",
    "                    if metric == 'cosine':\n",
    "                        dist = cosine(centroid1, centroid2)\n",
    "                    else:  # euclidean\n",
    "                        dist = np.linalg.norm(centroid1 - centroid2)\n",
    "                    distances.append(dist)\n",
    "            \n",
    "            if distances:\n",
    "                rdm_by_age[i, j] = np.mean(distances)\n",
    "                count_matrix_age[i, j] = len(distances)\n",
    "    \n",
    "    # ===== RDM 2: Average across ages for each category =====\n",
    "    # Create matrix: rows and columns are (category, location) pairs\n",
    "    category_location_pairs = [(cat, loc) for cat in categories for loc in locations]\n",
    "    n_cat_pairs = len(category_location_pairs)\n",
    "    \n",
    "    rdm_by_category = np.zeros((n_cat_pairs, n_cat_pairs))\n",
    "    count_matrix_category = np.zeros((n_cat_pairs, n_cat_pairs))\n",
    "    \n",
    "    for i, (cat1, loc1) in enumerate(category_location_pairs):\n",
    "        for j, (cat2, loc2) in enumerate(category_location_pairs):\n",
    "            distances = []\n",
    "            \n",
    "            # Average across all ages\n",
    "            for age in ages:\n",
    "                centroid1 = output_centroids.get((age, loc1, cat1))\n",
    "                centroid2 = output_centroids.get((age, loc2, cat2))\n",
    "                \n",
    "                if centroid1 is not None and centroid2 is not None:\n",
    "                    if metric == 'cosine':\n",
    "                        dist = cosine(centroid1, centroid2)\n",
    "                    else:  # euclidean\n",
    "                        dist = np.linalg.norm(centroid1 - centroid2)\n",
    "                    distances.append(dist)\n",
    "            \n",
    "            if distances:\n",
    "                rdm_by_category[i, j] = np.mean(distances)\n",
    "                count_matrix_category[i, j] = len(distances)\n",
    "    \n",
    "    return rdm_by_age, rdm_by_category, age_location_pairs, category_location_pairs, categories\n",
    "\n",
    "\n",
    "def plot_rdms(rdm_by_age, rdm_by_category, age_location_pairs, category_location_pairs, \n",
    "              categories, output_centroids, output_dir='rdm_plots', metric='cosine'):\n",
    "    \"\"\"\n",
    "    Plot the RDMs with appropriate labels.\n",
    "    \"\"\"\n",
    "    import os\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Extract unique ages and locations\n",
    "    ages = sorted(list(set([k[0] for k in output_centroids.keys() if output_centroids[k] is not None])))\n",
    "    locations = sorted(list(set([k[1] for k in output_centroids.keys() if output_centroids[k] is not None])))\n",
    "    ages = [age for age in ages if age >= 4 and age <= 9]  # Filter to include only ages 4-9\n",
    "    animal_categories = [\"bird\", \"rabbit\", \"cat\"]\n",
    "    n_animals = len([c for c in categories if c in animal_categories])\n",
    "    \n",
    "    # ===== Plot RDM by Age =====\n",
    "    fig, ax = plt.subplots(figsize=(14, 12))\n",
    "    \n",
    "    # Create labels for age-location pairs\n",
    "    age_loc_labels = [f\"{age}\\n{loc}\" for age, loc in age_location_pairs]\n",
    "    \n",
    "    sns.heatmap(rdm_by_age, annot=False, cmap='viridis', square=True,\n",
    "                xticklabels=age_loc_labels, yticklabels=age_loc_labels,\n",
    "                cbar_kws={'label': f'{metric.capitalize()} Distance'},\n",
    "                ax=ax)\n",
    "    \n",
    "    ax.set_title(f'RDM: Average Across All Categories by Age and Location\\n({metric} distance)', \n",
    "                 fontsize=16, pad=20)\n",
    "    ax.set_xlabel('Age - Location', fontsize=12)\n",
    "    ax.set_ylabel('Age - Location', fontsize=12)\n",
    "    \n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_dir}/rdm_by_age_{metric}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"Saved RDM by age\")\n",
    "    \n",
    "    # ===== Plot RDM by Category =====\n",
    "    fig, ax = plt.subplots(figsize=(16, 14))\n",
    "    \n",
    "    # Create labels for category-location pairs\n",
    "    cat_loc_labels = [f\"{cat}\\n{loc}\" for cat, loc in category_location_pairs]\n",
    "    \n",
    "    sns.heatmap(rdm_by_category, annot=False, cmap='viridis', square=True,\n",
    "                xticklabels=cat_loc_labels, yticklabels=cat_loc_labels,\n",
    "                cbar_kws={'label': f'{metric.capitalize()} Distance'},\n",
    "                ax=ax)\n",
    "    \n",
    "    # Draw lines to separate animals from non-animals\n",
    "    n_locations_count = len(set([loc for _, loc in category_location_pairs]))\n",
    "    animal_boundary = n_animals * n_locations_count\n",
    "    \n",
    "    ax.axhline(y=animal_boundary, color='red', linewidth=2, linestyle='--', alpha=0.7)\n",
    "    ax.axvline(x=animal_boundary, color='red', linewidth=2, linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Add text labels for animal/non-animal regions\n",
    "    ax.text(animal_boundary / 2, -1, 'Animals', ha='center', va='bottom', \n",
    "            fontsize=12, fontweight='bold', color='red')\n",
    "    ax.text(animal_boundary + (len(cat_loc_labels) - animal_boundary) / 2, -1, \n",
    "            'Non-Animals', ha='center', va='bottom', fontsize=12, fontweight='bold', color='red')\n",
    "    \n",
    "    ax.set_title(f'RDM: Average Across All Ages by Category and Location\\n({metric} distance)', \n",
    "                 fontsize=16, pad=20)\n",
    "    ax.set_xlabel('Category - Location', fontsize=12)\n",
    "    ax.set_ylabel('Category - Location', fontsize=12)\n",
    "    \n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_dir}/rdm_by_category_{metric}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"Saved RDM by category\")\n",
    "    \n",
    "    # ===== Plot simplified RDM: just categories (averaged across locations AND ages) =====\n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "    \n",
    "    # Compute category-only RDM by averaging across all age-location combinations\n",
    "    n_cats = len(categories)\n",
    "    rdm_category_only = np.zeros((n_cats, n_cats))\n",
    "    \n",
    "    n_locations_actual = len(set([loc for _, loc in category_location_pairs]))\n",
    "    \n",
    "    for i, cat1 in enumerate(categories):\n",
    "        for j, cat2 in enumerate(categories):\n",
    "            # Collect all distances between these two categories across all locations\n",
    "            distances = []\n",
    "            for loc_idx in range(n_locations_actual):\n",
    "                i_full = i * n_locations_actual + loc_idx\n",
    "                j_full = j * n_locations_actual + loc_idx\n",
    "                if i_full < rdm_by_category.shape[0] and j_full < rdm_by_category.shape[1]:\n",
    "                    distances.append(rdm_by_category[i_full, j_full])\n",
    "            \n",
    "            if distances:\n",
    "                rdm_category_only[i, j] = np.mean(distances)\n",
    "    \n",
    "    sns.heatmap(rdm_category_only, annot=True, fmt='.3f', cmap='viridis', square=True,\n",
    "                xticklabels=[c.capitalize() for c in categories], \n",
    "                yticklabels=[c.capitalize() for c in categories],\n",
    "                cbar_kws={'label': f'{metric.capitalize()} Distance'},\n",
    "                ax=ax)\n",
    "    \n",
    "    # Draw line to separate animals from non-animals\n",
    "    ax.axhline(y=n_animals, color='red', linewidth=2, linestyle='--', alpha=0.7)\n",
    "    ax.axvline(x=n_animals, color='red', linewidth=2, linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Add region labels\n",
    "    #ax.text(n_animals / 2, -0.5, 'Animals', ha='center', va='bottom', \n",
    "    #        fontsize=12, fontweight='bold', color='red')\n",
    "    #ax.text(n_animals + (n_cats - n_animals) / 2, -0.5, 'Non-Animals', \n",
    "    #        ha='center', va='bottom', fontsize=12, fontweight='bold', color='red')\n",
    "    \n",
    "    ax.set_title(f'RDM: Categories (averaged across ages and locations)\\n({metric} distance)', \n",
    "                 fontsize=16, pad=20)\n",
    "    ax.set_xlabel('Category', fontsize=10)\n",
    "    ax.set_ylabel('Category', fontsize=10)\n",
    "    \n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_dir}/rdm_category_only_{metric}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"Saved simplified category RDM\")\n",
    "    \n",
    "    # ===== Plot RDM by Category for each Age separately =====\n",
    "    for age in ages:\n",
    "        fig, ax = plt.subplots(figsize=(14, 12))\n",
    "        \n",
    "        # Build RDM for this age across all categories and locations\n",
    "        cat_loc_pairs_age = [(cat, loc) for cat in categories for loc in locations]\n",
    "        n_pairs = len(cat_loc_pairs_age)\n",
    "        rdm_age_specific = np.zeros((n_pairs, n_pairs))\n",
    "        \n",
    "        for i, (cat1, loc1) in enumerate(cat_loc_pairs_age):\n",
    "            for j, (cat2, loc2) in enumerate(cat_loc_pairs_age):\n",
    "                centroid1 = output_centroids.get((age, loc1, cat1))\n",
    "                centroid2 = output_centroids.get((age, loc2, cat2))\n",
    "                \n",
    "                if centroid1 is not None and centroid2 is not None:\n",
    "                    if metric == 'cosine':\n",
    "                        dist = cosine(centroid1, centroid2)\n",
    "                    else:  # euclidean\n",
    "                        dist = np.linalg.norm(centroid1 - centroid2)\n",
    "                    rdm_age_specific[i, j] = dist\n",
    "                else:\n",
    "                    rdm_age_specific[i, j] = np.nan\n",
    "        \n",
    "        # Create labels\n",
    "        cat_loc_labels_age = [f\"{cat}-{loc}\" for cat, loc in cat_loc_pairs_age]\n",
    "        \n",
    "        sns.heatmap(rdm_age_specific, annot=False, cmap='viridis', square=True,\n",
    "                    xticklabels=cat_loc_labels_age, yticklabels=cat_loc_labels_age,\n",
    "                    cbar_kws={'label': f'{metric.capitalize()} Distance'},\n",
    "                    ax=ax, mask=np.isnan(rdm_age_specific))\n",
    "        \n",
    "        # Draw lines to separate animals from non-animals\n",
    "        animal_boundary_age = n_animals * len(locations)\n",
    "        ax.axhline(y=animal_boundary_age, color='red', linewidth=2, linestyle='--', alpha=0.7)\n",
    "        ax.axvline(x=animal_boundary_age, color='red', linewidth=2, linestyle='--', alpha=0.7)\n",
    "        \n",
    "        # Add text labels\n",
    "        #ax.text(animal_boundary_age / 2, -1, 'Animals', ha='center', va='bottom', \n",
    "        #        fontsize=12, fontweight='bold', color='red')\n",
    "        #ax.text(animal_boundary_age + (n_pairs - animal_boundary_age) / 2, -1, \n",
    "        #        'Non-Animals', ha='center', va='bottom', fontsize=12, fontweight='bold', color='red')\n",
    "        \n",
    "        ax.set_title(f'RDM: All Categories by Location (Age {age})\\n({metric} distance)', \n",
    "                     fontsize=16, pad=20)\n",
    "        ax.set_xlabel('Category - Location', fontsize=12)\n",
    "        ax.set_ylabel('Category - Location', fontsize=12)\n",
    "        \n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.yticks(rotation=0)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{output_dir}/rdm_age_{age}_all_categories_{metric}.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"Saved RDM for age {age}\")\n",
    "    \n",
    "    # ===== Plot simplified RDM by Category for each Age (averaged across locations) =====\n",
    "    for age in ages:\n",
    "        fig, ax = plt.subplots(figsize=(12, 10))\n",
    "        \n",
    "        # Build category-only RDM for this age\n",
    "        n_cats = len(categories)\n",
    "        rdm_cat_age = np.zeros((n_cats, n_cats))\n",
    "        count_matrix = np.zeros((n_cats, n_cats))\n",
    "        \n",
    "        for i, cat1 in enumerate(categories):\n",
    "            for j, cat2 in enumerate(categories):\n",
    "                distances = []\n",
    "                for loc in locations:\n",
    "                    centroid1 = output_centroids.get((age, loc, cat1))\n",
    "                    centroid2 = output_centroids.get((age, loc, cat2))\n",
    "                    \n",
    "                    if centroid1 is not None and centroid2 is not None:\n",
    "                        if metric == 'cosine':\n",
    "                            dist = cosine(centroid1, centroid2)\n",
    "                        else:\n",
    "                            dist = np.linalg.norm(centroid1 - centroid2)\n",
    "                        distances.append(dist)\n",
    "                \n",
    "                if distances:\n",
    "                    rdm_cat_age[i, j] = np.mean(distances)\n",
    "                    count_matrix[i, j] = len(distances)\n",
    "                else:\n",
    "                    rdm_cat_age[i, j] = np.nan\n",
    "        \n",
    "        sns.heatmap(rdm_cat_age, annot=True, fmt='.3f', cmap='viridis', square=True,\n",
    "                    xticklabels=[c.capitalize() for c in categories], \n",
    "                    yticklabels=[c.capitalize() for c in categories],\n",
    "                    cbar_kws={'label': f'{metric.capitalize()} Distance'},\n",
    "                    ax=ax, mask=np.isnan(rdm_cat_age))\n",
    "        \n",
    "        # Draw line to separate animals from non-animals\n",
    "        ax.axhline(y=n_animals, color='red', linewidth=2, linestyle='--', alpha=0.7)\n",
    "        ax.axvline(x=n_animals, color='red', linewidth=2, linestyle='--', alpha=0.7)\n",
    "        \n",
    "        # Add region labels\n",
    "        ax.text(n_animals / 2, -0.5, 'Animals', ha='center', va='bottom', \n",
    "                fontsize=12, fontweight='bold', color='red')\n",
    "        ax.text(n_animals + (n_cats - n_animals) / 2, -0.5, 'Non-Animals', \n",
    "                ha='center', va='bottom', fontsize=12, fontweight='bold', color='red')\n",
    "        \n",
    "        ax.set_title(f'RDM: Categories (Age {age}, averaged across locations)\\n({metric} distance)', \n",
    "                     fontsize=16, pad=20)\n",
    "        ax.set_xlabel('Category', fontsize=12)\n",
    "        ax.set_ylabel('Category', fontsize=12)\n",
    "        \n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.yticks(rotation=0)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{output_dir}/rdm_age_{age}_categories_only_{metric}.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"Saved simplified category RDM for age {age}\")\n",
    "\n",
    "\n",
    "# Example sanjosege:\n",
    "rdm_by_age, rdm_by_category, age_loc_pairs, cat_loc_pairs, categories = create_rdm_from_centroids(\n",
    "     output_centroids, metric='cosine')\n",
    "\n",
    "plot_rdms(rdm_by_age, rdm_by_category, age_loc_pairs, cat_loc_pairs, \n",
    "          categories, output_centroids, metric='cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing airplane...\n",
      "Running t-SNE for airplane...\n",
      "Saved visualization for airplane\n",
      "Processing bike...\n",
      "Running t-SNE for bike...\n",
      "Saved visualization for bike\n",
      "Processing bird...\n",
      "Running t-SNE for bird...\n",
      "Saved visualization for bird\n",
      "Processing hat...\n",
      "Running t-SNE for hat...\n",
      "Saved visualization for hat\n",
      "Processing rabbit...\n",
      "Running t-SNE for rabbit...\n",
      "Saved visualization for rabbit\n",
      "Processing watch...\n",
      "Running t-SNE for watch...\n",
      "Saved visualization for watch\n",
      "Processing cat...\n",
      "Running t-SNE for cat...\n",
      "Saved visualization for cat\n",
      "Processing house...\n",
      "Running t-SNE for house...\n",
      "Saved visualization for house\n",
      "Processing cup...\n",
      "Running t-SNE for cup...\n",
      "Saved visualization for cup\n",
      "Processing chair...\n",
      "Running t-SNE for chair...\n",
      "Saved visualization for chair\n",
      "Processing tree...\n",
      "Running t-SNE for tree...\n",
      "Saved visualization for tree\n",
      "Processing car...\n",
      "Running t-SNE for car...\n",
      "Saved visualization for car\n"
     ]
    }
   ],
   "source": [
    "stores = {\n",
    "    'kisumu': kisumu_store,\n",
    "    'beijing': beijing_store,\n",
    "    'sanjose': sanjose_store,\n",
    "    'newdelhi': newdelhi_store\n",
    "}\n",
    "emb_df = collect_all_embeddings(recognizability_df, stores['kisumu'], stores['beijing'], \n",
    "                                 stores['sanjose'], stores['newdelhi'])\n",
    "emb_df = emb_df[(emb_df['age'] >= 4) & (emb_df['age'] <= 9)]\n",
    "emb_df = emb_df[emb_df['category'].isin(selected_categories)]\n",
    "\n",
    "create_tsne_per_category(recognizability_df, stores, centroid_urls=output_centroid_urls, emb_df=emb_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing age 4...\n",
      "Running t-SNE for age 4...\n",
      "Saved visualization for age 4\n",
      "Processing age 5...\n",
      "Running t-SNE for age 5...\n",
      "Saved visualization for age 5\n",
      "Processing age 6...\n",
      "Running t-SNE for age 6...\n",
      "Saved visualization for age 6\n",
      "Processing age 7...\n",
      "Running t-SNE for age 7...\n",
      "Saved visualization for age 7\n",
      "Processing age 8...\n",
      "Running t-SNE for age 8...\n",
      "Saved visualization for age 8\n",
      "Processing age 9...\n",
      "Running t-SNE for age 9...\n",
      "Saved visualization for age 9\n"
     ]
    }
   ],
   "source": [
    "create_tsne_per_age(recognizability_df, stores, emb_df=emb_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running t-SNE for all embeddings...\n",
      "Saved visualization for all embeddings\n"
     ]
    }
   ],
   "source": [
    "create_tsne_all_embeddings(recognizability_df, stores, emb_df=emb_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in df_all[df_all['category'] == 'bike'].iterrows():\n",
    "    os.makedirs(\"../data/examples/bike\", exist_ok=True)\n",
    "    ImageExtractor.save_transformed(str(row['url']), f\"../data/examples/bike/centroid_{row['location']}_{str(row['age'])}.png\", general_extraction_settings if row['location'] != \"Kisumu\" else kisumu_extraction_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just storing the file names as the drawing ID for ease of use and understanding and because they are unique. Maybe we want to include the parent directory too so that it's easy to remap back to the urls and so that it's more clear how they're different since they have different file naming conventions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vllpy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
